{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory task initial data exploration\n",
    "## Matt Oberhardt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import synapseclient\n",
    "from synapseclient import Project, Folder, File\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%matplotlib inline  \n",
    "# from pandas import DataFrame, Series\n",
    "np.set_printoptions(threshold='nan') # so that i can print as many lines as i want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import memorytools as mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the memory & demographic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Matthew Oberhardt!\n",
      "(phones are now filtered for only the most popular ones)\n"
     ]
    }
   ],
   "source": [
    "# initialize environment:\n",
    "synuser = os.environ['SYNAPSE_USER']\n",
    "synpass = os.environ['SYNAPSE_PASS']\n",
    "mt.loadSynapseRecordsFromScratch = False\n",
    "syn, memory, memorysyn, filePaths, demographics, demosyn, data = mt.create_memory_environment(synuser, synpass)\n",
    "data = mt.filter_data_for_popular_phones(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory features loaded from file: memory_data_with_features.p (input data was ignored)\n",
      "Warning: need to deal with case where meansuccessfuldist > meanunsuccessfuldist, e.g., with record 7944 (1st 16-box game)\n"
     ]
    }
   ],
   "source": [
    "# pull out features from games:\n",
    "fromFile = True#False\n",
    "toSave = False#True\n",
    "data = mt.add_memory_game_features_to_data(filePaths, data, fromFile = fromFile, toSave=toSave, outFileName='memory_data_with_features.p')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualize the memory data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordId\n",
      "healthCode\n",
      "createdOn\n",
      "appVersion\n",
      "phoneInfo\n",
      "game_score\n",
      "game_numGames\n",
      "game_numFails\n",
      "game_startDate\n",
      "game_endDate\n",
      "game_records\n",
      "medTimepoint\n",
      "game_records_txt\n",
      "recordId_demographic\n",
      "createdOn_demographic\n",
      "appVersion_demographic\n",
      "phoneInfo_demographic\n",
      "age\n",
      "isCaretaker\n",
      "brainStim\n",
      "diagYear\n",
      "education\n",
      "employment\n",
      "gender\n",
      "healthHistory\n",
      "healthcareProvider\n",
      "homeUsage\n",
      "lastSmoked\n",
      "maritalStatus\n",
      "medicalUsage\n",
      "medicalUsageYesterday\n",
      "medicationStartYear\n",
      "onsetYear\n",
      "packsPerDay\n",
      "pastParticipation\n",
      "phoneUsage\n",
      "professionalDiagnosis\n",
      "race\n",
      "smartphone\n",
      "smoked\n",
      "surgery\n",
      "videoUsage\n",
      "yearsSmoking\n",
      "hasParkinsons\n",
      "gamesdata\n",
      "16_latency\n",
      "16_gamescore\n",
      "16_successful\n",
      "16_meanDt\n",
      "16_meandist\n",
      "16_gamesize\n",
      "16_meanunsuccessfuldist\n",
      "16_meansuccessfuldist\n",
      "16_numunsuccesses\n",
      "16_numsuccesses\n",
      "16_firstdist\n",
      "9_latency\n",
      "9_gamescore\n",
      "9_successful\n",
      "9_meanDt\n",
      "9_meandist\n",
      "9_gamesize\n",
      "9_meanunsuccessfuldist\n",
      "9_meansuccessfuldist\n",
      "9_numunsuccesses\n",
      "9_numsuccesses\n",
      "9_firstdist\n",
      "4_latency\n",
      "4_gamescore\n",
      "4_successful\n",
      "4_meanDt\n",
      "4_meandist\n",
      "4_gamesize\n",
      "4_meanunsuccessfuldist\n",
      "4_meansuccessfuldist\n",
      "4_numunsuccesses\n",
      "4_numsuccesses\n",
      "4_firstdist\n"
     ]
    }
   ],
   "source": [
    "# columns:\n",
    "for col in data.columns:\n",
    "    print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls per column:\n",
      "\n",
      "recordId                               0\n",
      "gamesdata                              0\n",
      "hasParkinsons                          0\n",
      "phoneInfo_demographic                  0\n",
      "appVersion_demographic                 0\n",
      "createdOn_demographic                  0\n",
      "recordId_demographic                   0\n",
      "game_records_txt                       0\n",
      "game_records                           0\n",
      "parkinsons_meds_vs_nonparkinsons       0\n",
      "game_startDate                         0\n",
      "game_endDate                           0\n",
      "createdOn                              0\n",
      "appVersion                             0\n",
      "phoneInfo                              0\n",
      "healthCode                             0\n",
      "game_numGames                          0\n",
      "game_score                             0\n",
      "game_numFails                          0\n",
      "9_firstdist                            2\n",
      "9_latency                              2\n",
      "9_gamescore                            2\n",
      "9_successful                           2\n",
      "9_gamesize                             2\n",
      "9_meandist                             2\n",
      "9_numsuccesses                         2\n",
      "9_numunsuccesses                       2\n",
      "medTimepoint                           4\n",
      "smartphone                             5\n",
      "gender                                 5\n",
      "phoneUsage                             6\n",
      "9_meanDt                               6\n",
      "9_meansuccessfuldist                   7\n",
      "education                              8\n",
      "age                                   15\n",
      "pastParticipation                     16\n",
      "homeUsage                             16\n",
      "maritalStatus                         18\n",
      "employment                            19\n",
      "professionalDiagnosis                 21\n",
      "medicalUsage                          21\n",
      "isCaretaker                           22\n",
      "smoked                                51\n",
      "medicalUsageYesterday                 58\n",
      "race                                  79\n",
      "16_firstdist                         132\n",
      "16_numsuccesses                      132\n",
      "16_numunsuccesses                    132\n",
      "16_gamesize                          132\n",
      "16_successful                        132\n",
      "16_meandist                          132\n",
      "16_latency                           132\n",
      "16_gamescore                         132\n",
      "videoUsage                           142\n",
      "brainStim                            221\n",
      "16_meanDt                            285\n",
      "16_meansuccessfuldist                286\n",
      "surgery                              521\n",
      "16_meanunsuccessfuldist              735\n",
      "medicationStartYear                 1143\n",
      "healthHistory                       1180\n",
      "healthcareProvider                  1389\n",
      "onsetYear                           1414\n",
      "diagYear                            1722\n",
      "yearsSmoking                        5488\n",
      "lastSmoked                          5559\n",
      "packsPerDay                         5823\n",
      "9_meanunsuccessfuldist              6905\n",
      "4_numsuccesses                      7671\n",
      "4_numunsuccesses                    7671\n",
      "4_gamesize                          7671\n",
      "4_successful                        7671\n",
      "4_gamescore                         7671\n",
      "4_firstdist                         7671\n",
      "4_meandist                          7671\n",
      "4_latency                           7671\n",
      "4_meanDt                            7677\n",
      "4_meansuccessfuldist                7679\n",
      "4_meanunsuccessfuldist              7832\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How many nans in each column?\n",
    "mt.display_num_nulls_per_column(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16_meansuccessfuldist</th>\n",
       "      <th>16_meanunsuccessfuldist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.358862</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.521532</td>\n",
       "      <td>20.084539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.336439</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.941889</td>\n",
       "      <td>7.158911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.392725</td>\n",
       "      <td>5.700877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.614178</td>\n",
       "      <td>9.154410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.712571</td>\n",
       "      <td>10.793517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.505196</td>\n",
       "      <td>8.697732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.769258</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.523051</td>\n",
       "      <td>8.678291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.148643</td>\n",
       "      <td>12.103718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.977367</td>\n",
       "      <td>18.454298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.229619</td>\n",
       "      <td>12.206556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.650765</td>\n",
       "      <td>17.464249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.019847</td>\n",
       "      <td>8.378126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.184858</td>\n",
       "      <td>6.708204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.054734</td>\n",
       "      <td>12.505128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.515609</td>\n",
       "      <td>15.297059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.543396</td>\n",
       "      <td>18.901058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.344428</td>\n",
       "      <td>9.617692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.265673</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.163048</td>\n",
       "      <td>10.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.431056</td>\n",
       "      <td>12.079949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.714907</td>\n",
       "      <td>11.884864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.302350</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11.070172</td>\n",
       "      <td>10.731456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.555475</td>\n",
       "      <td>17.102631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.961172</td>\n",
       "      <td>3.201562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16.031220</td>\n",
       "      <td>17.534283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.253904</td>\n",
       "      <td>12.589678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.956544</td>\n",
       "      <td>19.319679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.670266</td>\n",
       "      <td>2.121320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.854808</td>\n",
       "      <td>15.041609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.710194</td>\n",
       "      <td>8.944272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.699247</td>\n",
       "      <td>9.340771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11.325309</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12.543110</td>\n",
       "      <td>11.543396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8.786871</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13.935577</td>\n",
       "      <td>13.086252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>12.967071</td>\n",
       "      <td>4.478339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>12.118825</td>\n",
       "      <td>23.037404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7843</th>\n",
       "      <td>20.404721</td>\n",
       "      <td>20.666018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844</th>\n",
       "      <td>11.518930</td>\n",
       "      <td>28.012903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7845</th>\n",
       "      <td>14.039086</td>\n",
       "      <td>7.158911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>8.980387</td>\n",
       "      <td>5.700877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7847</th>\n",
       "      <td>12.862648</td>\n",
       "      <td>16.978175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7848</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>3.041381</td>\n",
       "      <td>8.077747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>11.804383</td>\n",
       "      <td>45.124827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15.008331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>7.759467</td>\n",
       "      <td>9.013878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853</th>\n",
       "      <td>15.475193</td>\n",
       "      <td>18.560711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7854</th>\n",
       "      <td>14.040080</td>\n",
       "      <td>8.972173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>12.085544</td>\n",
       "      <td>5.798658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>9.484335</td>\n",
       "      <td>7.158911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>15.605210</td>\n",
       "      <td>27.134438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928</th>\n",
       "      <td>12.340025</td>\n",
       "      <td>4.924429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>17.162365</td>\n",
       "      <td>32.407561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>12.865624</td>\n",
       "      <td>24.358033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>9.918424</td>\n",
       "      <td>13.829317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>8.167273</td>\n",
       "      <td>9.656604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>8.398124</td>\n",
       "      <td>9.433981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>11.140732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>11.332539</td>\n",
       "      <td>4.116372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7965</th>\n",
       "      <td>15.166587</td>\n",
       "      <td>8.381527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7966</th>\n",
       "      <td>5.862824</td>\n",
       "      <td>4.828583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7967</th>\n",
       "      <td>15.990219</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>20.089871</td>\n",
       "      <td>14.340734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7969</th>\n",
       "      <td>17.449997</td>\n",
       "      <td>8.834916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>22.251982</td>\n",
       "      <td>15.508062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>12.484655</td>\n",
       "      <td>19.163768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>15.946361</td>\n",
       "      <td>14.773287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>11.926674</td>\n",
       "      <td>10.965856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>12.146479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>13.187475</td>\n",
       "      <td>9.055385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>10.003059</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>10.045403</td>\n",
       "      <td>10.572443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7854 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      16_meansuccessfuldist  16_meanunsuccessfuldist\n",
       "0                 16.358862                      NaN\n",
       "1                 17.521532                20.084539\n",
       "2                  9.336439                12.500000\n",
       "3                 12.941889                 7.158911\n",
       "4                 11.392725                 5.700877\n",
       "5                 11.614178                 9.154410\n",
       "6                 10.712571                10.793517\n",
       "7                 13.505196                 8.697732\n",
       "8                  9.769258                 1.581139\n",
       "9                 12.523051                 8.678291\n",
       "10                11.148643                12.103718\n",
       "11                12.977367                18.454298\n",
       "12                14.229619                12.206556\n",
       "13                15.650765                17.464249\n",
       "14                11.019847                 8.378126\n",
       "15                12.184858                 6.708204\n",
       "16                12.054734                12.505128\n",
       "17                 9.515609                15.297059\n",
       "18                11.543396                18.901058\n",
       "19                17.344428                 9.617692\n",
       "20                 9.265673                 3.500000\n",
       "21                12.163048                10.000374\n",
       "22                 6.431056                12.079949\n",
       "23                 8.714907                11.884864\n",
       "24                13.302350                 5.000000\n",
       "25                11.070172                10.731456\n",
       "26                10.555475                17.102631\n",
       "27                 7.961172                 3.201562\n",
       "28                16.031220                17.534283\n",
       "29                11.253904                12.589678\n",
       "30                11.956544                19.319679\n",
       "31                 7.670266                 2.121320\n",
       "32                13.854808                15.041609\n",
       "33                 7.710194                 8.944272\n",
       "34                10.699247                 9.340771\n",
       "35                11.325309                      NaN\n",
       "36                12.543110                11.543396\n",
       "37                 8.786871                      NaN\n",
       "38                13.935577                13.086252\n",
       "...                     ...                      ...\n",
       "7841              12.967071                 4.478339\n",
       "7842              12.118825                23.037404\n",
       "7843              20.404721                20.666018\n",
       "7844              11.518930                28.012903\n",
       "7845              14.039086                 7.158911\n",
       "7846               8.980387                 5.700877\n",
       "7847              12.862648                16.978175\n",
       "7848                    NaN                      NaN\n",
       "7849               3.041381                 8.077747\n",
       "7850              11.804383                45.124827\n",
       "7851                    NaN                15.008331\n",
       "7852               7.759467                 9.013878\n",
       "7853              15.475193                18.560711\n",
       "7854              14.040080                 8.972173\n",
       "7906              12.085544                 5.798658\n",
       "7907               9.484335                 7.158911\n",
       "7913              15.605210                27.134438\n",
       "7928              12.340025                 4.924429\n",
       "7929              17.162365                32.407561\n",
       "7930              12.865624                24.358033\n",
       "7931               9.918424                13.829317\n",
       "7932               8.167273                 9.656604\n",
       "7933               8.398124                 9.433981\n",
       "7940              11.140732                      NaN\n",
       "7944              11.332539                 4.116372\n",
       "7945                    NaN                      NaN\n",
       "7965              15.166587                 8.381527\n",
       "7966               5.862824                 4.828583\n",
       "7967              15.990219                      NaN\n",
       "7968              20.089871                14.340734\n",
       "7969              17.449997                 8.834916\n",
       "7970              22.251982                15.508062\n",
       "7971              12.484655                19.163768\n",
       "7972              15.946361                14.773287\n",
       "7973              11.926674                10.965856\n",
       "7976              12.146479                      NaN\n",
       "7977              13.187475                 9.055385\n",
       "7978              10.003059                 1.000000\n",
       "7979              10.045403                10.572443\n",
       "\n",
       "[7854 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['16_meansuccessfuldist','16_meanunsuccessfuldist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e5c2a729-d053-40eb-8a5f-2bef8515a8f6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{4: [],\n",
       " 9: [{u'MemoryGameRecordGameScore': 45,\n",
       "   u'MemoryGameRecordGameSize': 9,\n",
       "   u'MemoryGameRecordSeed': 597123000,\n",
       "   u'MemoryGameRecordSequence': [4, 5, 2],\n",
       "   u'MemoryGameRecordTargetRects': [u'{{36, 199}, {114, 114}}',\n",
       "    u'{{36, 313}, {114, 114}}',\n",
       "    u'{{36, 427}, {114, 114}}',\n",
       "    u'{{150, 199}, {114, 114}}',\n",
       "    u'{{150, 313}, {114, 114}}',\n",
       "    u'{{150, 427}, {114, 114}}',\n",
       "    u'{{264, 199}, {114, 114}}',\n",
       "    u'{{264, 313}, {114, 114}}',\n",
       "    u'{{264, 427}, {114, 114}}'],\n",
       "   u'MemoryGameRecordTouchSamples': [{u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{207.66667175292969, 376.33334350585938}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 4,\n",
       "     u'MemoryGameTouchSampleTimestamp': 0.8492842083214782},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{219.66667175292969, 493.66668701171875}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 5,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.249212541675661},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{81.666656494140625, 475}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 2,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.699139833333902}],\n",
       "   u'MemoryGameStatus': u'MemoryGameStatusSuccess'},\n",
       "  {u'MemoryGameRecordGameScore': 60,\n",
       "   u'MemoryGameRecordGameSize': 9,\n",
       "   u'MemoryGameRecordSeed': 770374868,\n",
       "   u'MemoryGameRecordSequence': [8, 2, 3, 1],\n",
       "   u'MemoryGameRecordTargetRects': [u'{{36, 199}, {114, 114}}',\n",
       "    u'{{36, 313}, {114, 114}}',\n",
       "    u'{{36, 427}, {114, 114}}',\n",
       "    u'{{150, 199}, {114, 114}}',\n",
       "    u'{{150, 313}, {114, 114}}',\n",
       "    u'{{150, 427}, {114, 114}}',\n",
       "    u'{{264, 199}, {114, 114}}',\n",
       "    u'{{264, 313}, {114, 114}}',\n",
       "    u'{{264, 427}, {114, 114}}'],\n",
       "   u'MemoryGameRecordTouchSamples': [{u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{330.33334350585938, 472.33331298828125}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 8,\n",
       "     u'MemoryGameTouchSampleTimestamp': 0.6360345833236352},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{96, 484.33331298828125}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 2,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.084792333364021},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{234, 248}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 3,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.502410541696008},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{80.333328247070312, 378}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 1,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.986015958362259}],\n",
       "   u'MemoryGameStatus': u'MemoryGameStatusSuccess'},\n",
       "  {u'MemoryGameRecordGameScore': 60,\n",
       "   u'MemoryGameRecordGameSize': 9,\n",
       "   u'MemoryGameRecordSeed': 2031791952,\n",
       "   u'MemoryGameRecordSequence': [1, 2, 3, 5],\n",
       "   u'MemoryGameRecordTargetRects': [u'{{36, 199}, {114, 114}}',\n",
       "    u'{{36, 313}, {114, 114}}',\n",
       "    u'{{36, 427}, {114, 114}}',\n",
       "    u'{{150, 199}, {114, 114}}',\n",
       "    u'{{150, 313}, {114, 114}}',\n",
       "    u'{{150, 427}, {114, 114}}',\n",
       "    u'{{264, 199}, {114, 114}}',\n",
       "    u'{{264, 313}, {114, 114}}',\n",
       "    u'{{264, 427}, {114, 114}}'],\n",
       "   u'MemoryGameRecordTouchSamples': [{u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{95, 360.66665649414062}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 1,\n",
       "     u'MemoryGameTouchSampleTimestamp': 0.6747110416763462},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{89, 476}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 2,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.007996041676961},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{213.33332824707031, 259}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 3,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.407907166634686},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{197.66667175292969, 480.33331298828125}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 5,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.774875624978449}],\n",
       "   u'MemoryGameStatus': u'MemoryGameStatusSuccess'}],\n",
       " 16: [{u'MemoryGameRecordGameScore': 15,\n",
       "   u'MemoryGameRecordGameSize': 16,\n",
       "   u'MemoryGameRecordSeed': 4078296992,\n",
       "   u'MemoryGameRecordSequence': [2, 0, 1, 3, 14],\n",
       "   u'MemoryGameRecordTargetRects': [u'{{21, 184}, {93, 93}}',\n",
       "    u'{{21, 277}, {93, 93}}',\n",
       "    u'{{21, 370}, {93, 93}}',\n",
       "    u'{{21, 463}, {93, 93}}',\n",
       "    u'{{114, 184}, {93, 93}}',\n",
       "    u'{{114, 277}, {93, 93}}',\n",
       "    u'{{114, 370}, {93, 93}}',\n",
       "    u'{{114, 463}, {93, 93}}',\n",
       "    u'{{207, 184}, {93, 93}}',\n",
       "    u'{{207, 277}, {93, 93}}',\n",
       "    u'{{207, 370}, {93, 93}}',\n",
       "    u'{{207, 463}, {93, 93}}',\n",
       "    u'{{300, 184}, {93, 93}}',\n",
       "    u'{{300, 277}, {93, 93}}',\n",
       "    u'{{300, 370}, {93, 93}}',\n",
       "    u'{{300, 463}, {93, 93}}'],\n",
       "   u'MemoryGameRecordTouchSamples': [{u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{68, 408.66665649414062}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 2,\n",
       "     u'MemoryGameTouchSampleTimestamp': 0.7851849166909233},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{76, 245.33334350585938}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 0,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.368405166664161},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': False,\n",
       "     u'MemoryGameTouchSampleLocation': u'{63.666656494140625, 508}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 3,\n",
       "     u'MemoryGameTouchSampleTimestamp': 2.318390291708056}],\n",
       "   u'MemoryGameStatus': u'MemoryGameStatusFailure'},\n",
       "  {u'MemoryGameRecordGameScore': 75,\n",
       "   u'MemoryGameRecordGameSize': 16,\n",
       "   u'MemoryGameRecordSeed': 3925392038,\n",
       "   u'MemoryGameRecordSequence': [3, 4, 10, 1, 6],\n",
       "   u'MemoryGameRecordTargetRects': [u'{{21, 184}, {93, 93}}',\n",
       "    u'{{21, 277}, {93, 93}}',\n",
       "    u'{{21, 370}, {93, 93}}',\n",
       "    u'{{21, 463}, {93, 93}}',\n",
       "    u'{{114, 184}, {93, 93}}',\n",
       "    u'{{114, 277}, {93, 93}}',\n",
       "    u'{{114, 370}, {93, 93}}',\n",
       "    u'{{114, 463}, {93, 93}}',\n",
       "    u'{{207, 184}, {93, 93}}',\n",
       "    u'{{207, 277}, {93, 93}}',\n",
       "    u'{{207, 370}, {93, 93}}',\n",
       "    u'{{207, 463}, {93, 93}}',\n",
       "    u'{{300, 184}, {93, 93}}',\n",
       "    u'{{300, 277}, {93, 93}}',\n",
       "    u'{{300, 370}, {93, 93}}',\n",
       "    u'{{300, 463}, {93, 93}}'],\n",
       "   u'MemoryGameRecordTouchSamples': [{u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{76.666656494140625, 507.33331298828125}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 3,\n",
       "     u'MemoryGameTouchSampleTimestamp': 0.563689999980852},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{145, 241.33334350585938}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 4,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.045768624986522},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{264, 415.33334350585938}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 10,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.530110666644759},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{59.333328247070312, 320.33334350585938}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 1,\n",
       "     u'MemoryGameTouchSampleTimestamp': 1.997012874984648},\n",
       "    {u'MemoryGameTouchSampleIsCorrect': True,\n",
       "     u'MemoryGameTouchSampleLocation': u'{158, 418.66665649414062}',\n",
       "     u'MemoryGameTouchSampleTargetIndex': 6,\n",
       "     u'MemoryGameTouchSampleTimestamp': 2.4635899583227}],\n",
       "   u'MemoryGameStatus': u'MemoryGameStatusSuccess'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at one record where meansuccessfuldist > meanunsuccessfuldist -- that is wierd (might be a bug)\n",
    "rowidx = 7944\n",
    "print data['recordId'][rowidx]\n",
    "games = data['gamesdata'][rowidx]['games_by_sizes']\n",
    "games\n",
    "#data['recordId'][rowidx]\n",
    "# problem here... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all memory features: {'latency': [0.7851849166909233, 0.563689999980852], 'gamescore': [15, 75], 'successful': [False, True], 'meanDt': [0.76660268750856631, 0.47497498958546203], 'meandist': [9.6872664794558148, 10.192365369093453], 'gamesize': [16, 16], 'meanunsuccessfuldist': [4.11637248483592, nan], 'meansuccessfuldist': [12.472713476765762, 10.192365369093453], 'numunsuccesses': [1, 0], 'numsuccesses': [2, 5], 'firstdist': [7.8492847114109221, 9.419242214123237]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'firstdist': 8.6342634627670805,\n",
       " 'gamescore': 45.0,\n",
       " 'gamesize': 16.0,\n",
       " 'latency': 0.67443745833588764,\n",
       " 'meanDt': 0.62078883854701417,\n",
       " 'meandist': 9.9398159242746331,\n",
       " 'meansuccessfuldist': 11.332539422929607,\n",
       " 'meanunsuccessfuldist': 4.11637248483592,\n",
       " 'numsuccesses': 3.5,\n",
       " 'numunsuccesses': 0.5,\n",
       " 'successful': 0.5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games16 = games[16]\n",
    "avg_memory_features = mt.average_features_from_memory_games(games16)\n",
    "\n",
    "#memory_features = mt.pull_features_from_memory_game(game)\n",
    "#memory_features\n",
    "\n",
    "%autoreload 2\n",
    "avg_memory_features\n",
    "## It seems that the MemoryGameTouchSampleIsCorrect field is WRONG here!?, for the 1st result from game 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "from sklearn.utils.validation import check_consistent_length, _num_samples\n",
    "import sklearn.preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick & process features, 1st logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features converted to numbers:\n",
      "\n",
      "['gender', 'phoneUsage', 'smartphone', 'education', 'phoneInfo']\n",
      "training accuracy: 0.888564654386\n",
      "test accuracy: 0.881327094853\n",
      "\n",
      "\n",
      "phoneUsage      -0.726648\n",
      "gender          -0.535846\n",
      "education       -0.091916\n",
      "game_score       0.030728\n",
      "game_numFails    0.104056\n",
      "phoneInfo        0.126661\n",
      "age              1.523501\n",
      "smartphone       1.527187\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##### define features:\n",
    "\n",
    "features = [\"game_score\",\"age\",\"game_numFails\", \"phoneInfo\",\n",
    "    \"education\", \"gender\", \"phoneUsage\", \"smartphone\", \"hasParkinsons\"]\n",
    "features_df = data[features]\n",
    "\n",
    "features_df = mt.convert_features_to_numbers(features_df)\n",
    "features_df = mt.move_col_to_end_of_df(features_df, 'hasParkinsons')\n",
    "\n",
    "# do more processing here, in case of features with lots of nas\n",
    "\n",
    "# drop na rows:\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# convert to matrices for machine learning:\n",
    "labelcol = 'hasParkinsons'\n",
    "X, y, X_names, y_name = mt.convert_features_df_to_X_and_y_for_machinelearning(features_df, labelcol)\n",
    "    \n",
    "###### perform logistic regression\n",
    "\n",
    "# do cross validation manually:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# scale features:\n",
    "stdsc = StandardScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# create logistic regression model:\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)##\n",
    "#lr = linear_model.LogisticRegression(penalty='l1', C=0.1) # with regularization\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "###### assess regression performance:\n",
    "lr.coef_\n",
    "lr.intercept_ # this is the 0 coeff?\n",
    "lr.fit(X_train_std, y_train)\n",
    "print 'training accuracy:', lr.score(X_train_std, y_train)\n",
    "print 'test accuracy:', lr.score(X_test_std, y_test) # suspiciously high..\n",
    "lr.intercept_\n",
    "lr.coef_ # only using 4 features.. which ones?\n",
    "# mt.plot_decision_regions(X_combined_std, y_combined_std, classifier=lr, test_idx=range(len(X_train_std),len(X_combined_std)+1))\n",
    "X_names_heavy = X_names[np.where(np.abs(lr.coef_) > 0.1)[1]]\n",
    "Scoef = mt.convert_regression_coefs_to_pdSeries(lr.coef_, X_names)\n",
    "\n",
    "print '\\n'\n",
    "print Scoef.sort_values()\n",
    "#print lr.score\n",
    "# tp / (tp + fn)\n",
    "\n",
    "# look at sklearn.metrics\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features converted to numbers:\n",
      "\n",
      "['gender', 'phoneUsage', 'smartphone', 'education', 'phoneInfo']\n",
      "training accuracy: 0.999452854277\n",
      "test accuracy: 0.977881752446\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'list'>\n",
      "0           [0.0, 1.0]\n",
      "1           [1.0, 0.0]\n",
      "2         [0.02, 0.98]\n",
      "3         [0.03, 0.97]\n",
      "4           [0.0, 1.0]\n",
      "5         [0.09, 0.91]\n",
      "6           [0.0, 1.0]\n",
      "7           [0.0, 1.0]\n",
      "8           [0.0, 1.0]\n",
      "9         [0.01, 0.99]\n",
      "10        [0.02, 0.98]\n",
      "11          [0.0, 1.0]\n",
      "12          [0.0, 1.0]\n",
      "13          [0.0, 1.0]\n",
      "14          [0.0, 1.0]\n",
      "15      [0.995, 0.005]\n",
      "16          [0.0, 1.0]\n",
      "17          [0.0, 1.0]\n",
      "18          [0.0, 1.0]\n",
      "19        [0.01, 0.99]\n",
      "20          [0.0, 1.0]\n",
      "21          [0.0, 1.0]\n",
      "22        [0.32, 0.68]\n",
      "23          [0.0, 1.0]\n",
      "24          [0.0, 1.0]\n",
      "25        [0.03, 0.97]\n",
      "26          [0.0, 1.0]\n",
      "27          [0.0, 1.0]\n",
      "28          [0.0, 1.0]\n",
      "29          [1.0, 0.0]\n",
      "30          [0.0, 1.0]\n",
      "31          [0.0, 1.0]\n",
      "32          [0.0, 1.0]\n",
      "33          [0.0, 1.0]\n",
      "34          [0.0, 1.0]\n",
      "35          [0.0, 1.0]\n",
      "36          [0.0, 1.0]\n",
      "37        [0.72, 0.28]\n",
      "38        [0.03, 0.97]\n",
      "             ...      \n",
      "2312      [0.85, 0.15]\n",
      "2313        [0.0, 1.0]\n",
      "2314      [0.01, 0.99]\n",
      "2315        [0.0, 1.0]\n",
      "2316        [0.0, 1.0]\n",
      "2317        [0.1, 0.9]\n",
      "2318        [0.0, 1.0]\n",
      "2319      [0.03, 0.97]\n",
      "2320        [0.0, 1.0]\n",
      "2321        [1.0, 0.0]\n",
      "2322        [0.0, 1.0]\n",
      "2323        [0.0, 1.0]\n",
      "2324      [0.63, 0.37]\n",
      "2325        [0.0, 1.0]\n",
      "2326        [0.0, 1.0]\n",
      "2327      [0.11, 0.89]\n",
      "2328        [0.0, 1.0]\n",
      "2329      [0.03, 0.97]\n",
      "2330      [0.11, 0.89]\n",
      "2331        [0.0, 1.0]\n",
      "2332        [0.0, 1.0]\n",
      "2333      [0.63, 0.37]\n",
      "2334        [0.9, 0.1]\n",
      "2335      [0.01, 0.99]\n",
      "2336        [0.0, 1.0]\n",
      "2337        [1.0, 0.0]\n",
      "2338        [0.0, 1.0]\n",
      "2339        [1.0, 0.0]\n",
      "2340        [0.0, 1.0]\n",
      "2341        [0.0, 1.0]\n",
      "2342        [0.0, 1.0]\n",
      "2343      [0.04, 0.96]\n",
      "2344        [0.0, 1.0]\n",
      "2345        [0.0, 1.0]\n",
      "2346        [0.0, 1.0]\n",
      "2347        [1.0, 0.0]\n",
      "2348        [0.0, 1.0]\n",
      "2349      [0.01, 0.99]\n",
      "2350        [0.0, 1.0]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "##### define features:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = [\"game_score\",\"age\",\"game_numFails\", \"phoneInfo\",\n",
    "    \"education\", \"gender\", \"phoneUsage\", \"smartphone\", \"hasParkinsons\"\n",
    "\n",
    "features_df = data[features]\n",
    "\n",
    "features_df = mt.convert_features_to_numbers(features_df)\n",
    "features_df = mt.move_col_to_end_of_df(features_df, 'hasParkinsons')\n",
    "\n",
    "# do more processing here, in case of features with lots of nas\n",
    "\n",
    "# drop na rows:\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# convert to matrices for machine learning:\n",
    "labelcol = 'hasParkinsons'\n",
    "X, y, X_names, y_name = mt.convert_features_df_to_X_and_y_for_machinelearning(features_df, labelcol)\n",
    "    \n",
    "###### perform logistic regression\n",
    "\n",
    "# do cross validation manually:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# scale features:\n",
    "stdsc = StandardScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# create logistic regression model:\n",
    "lr = RandomForestClassifier(n_estimators=100)\n",
    "#lr = linear_model.LogisticRegression(penalty='l1', C=0.1) # with regularization\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "###### assess regression performance:\n",
    "lr.fit(X_train_std, y_train)\n",
    "print 'training accuracy:', lr.score(X_train_std, y_train)\n",
    "print 'test accuracy:', lr.score(X_test_std, y_test) # suspiciously high..\n",
    "\n",
    "\n",
    "mat = lr.predict_proba(X_test_std)\n",
    "print mat.__class__\n",
    "inlist = mat.tolist()\n",
    "print inlist.__class__\n",
    "S = pd.Series(inlist)\n",
    "print S\n",
    "\n",
    "#print S\n",
    "#lr.feature_importances_\n",
    "\n",
    "# WORKS!!!!!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try logistic regression, inputting the hasParkinsons column as a feature\n",
    "#### (should give perfect prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:427: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features converted to numbers:\n",
      "\n",
      "['gender', 'phoneUsage', 'smartphone', 'education', 'phoneInfo']\n",
      "training accuracy: 1.0\n",
      "test accuracy: 1.0\n",
      "\n",
      "\n",
      "phoneUsage       -0.116390\n",
      "gender           -0.104257\n",
      "game_score       -0.069913\n",
      "education         0.006747\n",
      "game_numFails     0.077573\n",
      "phoneInfo         0.096486\n",
      "smartphone        0.187908\n",
      "age               0.625051\n",
      "hasParkinsons2    9.381030\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:427: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:427: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:427: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### define features:\n",
    "features = [\"game_score\",\"age\",\"game_numFails\", \"phoneInfo\",\n",
    "    \"education\", \"gender\", \"phoneUsage\", \"smartphone\", \"hasParkinsons\"]\n",
    "features_df = data[features]\n",
    "features_df['hasParkinsons2'] = data['hasParkinsons']\n",
    "\n",
    "features_df = mt.convert_features_to_numbers(features_df)\n",
    "features_df = mt.move_col_to_end_of_df(features_df, 'hasParkinsons')\n",
    "\n",
    "# do more processing here, in case of features with lots of nas\n",
    "\n",
    "# drop na rows:\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# convert to matrices for machine learning:\n",
    "labelcol = 'hasParkinsons'\n",
    "X, y, X_names, y_name = mt.convert_features_df_to_X_and_y_for_machinelearning(features_df, labelcol)\n",
    "    \n",
    "###### perform logistic regression\n",
    "\n",
    "# do cross validation manually:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# scale features:\n",
    "stdsc = StandardScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# create logistic regression model:\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)##\n",
    "#lr = linear_model.LogisticRegression(penalty='l1', C=0.1) # with regularization\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "###### assess regression performance:\n",
    "lr.coef_\n",
    "lr.intercept_ # this is the 0 coeff?\n",
    "lr.fit(X_train_std, y_train)\n",
    "print 'training accuracy:', lr.score(X_train_std, y_train)\n",
    "print 'test accuracy:', lr.score(X_test_std, y_test) # suspiciously high..\n",
    "lr.intercept_\n",
    "lr.coef_ # only using 4 features.. which ones?\n",
    "# mt.plot_decision_regions(X_combined_std, y_combined_std, classifier=lr, test_idx=range(len(X_train_std),len(X_combined_std)+1))\n",
    "X_names_heavy = X_names[np.where(np.abs(lr.coef_) > 0.1)[1]]\n",
    "Scoef = mt.convert_regression_coefs_to_pdSeries(lr.coef_, X_names)\n",
    "\n",
    "print '\\n'\n",
    "print Scoef.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### that works well. good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add memory features to model, & redo logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls per column:\n",
      "\n",
      "recordId                      0\n",
      "phoneInfo_demographic         0\n",
      "appVersion_demographic        0\n",
      "createdOn_demographic         0\n",
      "gamesdata                     0\n",
      "game_records_txt              0\n",
      "game_records                  0\n",
      "game_endDate                  0\n",
      "recordId_demographic          0\n",
      "game_numFails                 0\n",
      "game_startDate                0\n",
      "healthCode                    0\n",
      "createdOn                     0\n",
      "appVersion                    0\n",
      "hasParkinsons                 0\n",
      "game_score                    0\n",
      "game_numGames                 0\n",
      "phoneInfo                     0\n",
      "9_numsuccesses                2\n",
      "9_numunsuccesses              2\n",
      "9_gamesize                    2\n",
      "9_meandist                    2\n",
      "9_successful                  2\n",
      "9_gamescore                   2\n",
      "9_latency                     2\n",
      "9_firstdist                   2\n",
      "medTimepoint                  4\n",
      "smartphone                    5\n",
      "gender                        5\n",
      "phoneUsage                    6\n",
      "9_meanDt                      6\n",
      "9_meansuccessfuldist          7\n",
      "education                     8\n",
      "age                          15\n",
      "pastParticipation            16\n",
      "homeUsage                    16\n",
      "maritalStatus                18\n",
      "employment                   19\n",
      "medicalUsage                 21\n",
      "professionalDiagnosis        21\n",
      "isCaretaker                  22\n",
      "smoked                       51\n",
      "medicalUsageYesterday        58\n",
      "race                         79\n",
      "16_firstdist                132\n",
      "16_gamesize                 132\n",
      "16_meandist                 132\n",
      "16_numsuccesses             132\n",
      "16_gamescore                132\n",
      "16_latency                  132\n",
      "16_numunsuccesses           132\n",
      "16_successful               132\n",
      "videoUsage                  142\n",
      "brainStim                   221\n",
      "16_meanDt                   285\n",
      "16_meansuccessfuldist       286\n",
      "surgery                     521\n",
      "16_meanunsuccessfuldist     735\n",
      "medicationStartYear        1143\n",
      "healthHistory              1180\n",
      "healthcareProvider         1389\n",
      "onsetYear                  1414\n",
      "diagYear                   1722\n",
      "yearsSmoking               5488\n",
      "lastSmoked                 5559\n",
      "packsPerDay                5823\n",
      "9_meanunsuccessfuldist     6905\n",
      "4_numunsuccesses           7671\n",
      "4_gamesize                 7671\n",
      "4_meandist                 7671\n",
      "4_gamescore                7671\n",
      "4_successful               7671\n",
      "4_latency                  7671\n",
      "4_numsuccesses             7671\n",
      "4_firstdist                7671\n",
      "4_meanDt                   7677\n",
      "4_meansuccessfuldist       7679\n",
      "4_meanunsuccessfuldist     7832\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How many nans in each column?\n",
    "numnulls = data.isnull().sum()\n",
    "pd.set_option('display.max_rows', len(numnulls))\n",
    "numnulls.sort_values(inplace=True, ascending=True)\n",
    "print 'Number of nulls per column:\\n'\n",
    "print numnulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9_numsuccesses',\n",
       " '9_numunsuccesses',\n",
       " '9_gamesize',\n",
       " '9_meandist',\n",
       " '9_successful',\n",
       " '9_gamescore',\n",
       " '9_latency',\n",
       " '9_firstdist',\n",
       " 'game_score',\n",
       " 'age',\n",
       " 'game_numFails',\n",
       " 'phoneInfo',\n",
       " 'education',\n",
       " 'gender',\n",
       " 'phoneUsage',\n",
       " 'smartphone',\n",
       " 'hasParkinsons']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### define features:\n",
    "gamefeatures = ['9_numsuccesses', '9_numunsuccesses',\n",
    "                '9_gamesize', '9_meandist', '9_successful',\n",
    "                '9_gamescore', '9_latency', '9_firstdist']\n",
    "\n",
    "features = [\"game_score\",\"age\",\"game_numFails\", \"phoneInfo\",\n",
    "    \"education\", \"gender\", \"phoneUsage\", \"smartphone\", \"hasParkinsons\"]\n",
    "\n",
    "features = gamefeatures + features\n",
    "#features = gamefeatures + ['game_score', 'hasParkinsons']\n",
    "\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features converted to numbers:\n",
      "\n",
      "['gender', 'phoneUsage', 'smartphone', 'education', 'phoneInfo']\n",
      "training accuracy: 0.891645384896\n",
      "test accuracy: 0.891489361702\n",
      "\n",
      "\n",
      "9_gamescore        -0.925850\n",
      "phoneUsage         -0.750180\n",
      "gender             -0.584945\n",
      "9_latency          -0.172239\n",
      "education          -0.090453\n",
      "game_score         -0.041914\n",
      "9_gamesize          0.000000\n",
      "game_numFails       0.041078\n",
      "phoneInfo           0.059917\n",
      "9_firstdist         0.121477\n",
      "9_meandist          0.487042\n",
      "9_numsuccesses      0.589335\n",
      "9_numunsuccesses    1.111960\n",
      "9_successful        1.447958\n",
      "smartphone          1.449737\n",
      "age                 1.519702\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# transform features, etc.\n",
    "features_df = data[features]\n",
    "\n",
    "features_df = mt.convert_features_to_numbers(features_df)\n",
    "features_df = mt.move_col_to_end_of_df(features_df, 'hasParkinsons')\n",
    "\n",
    "# do more processing here, in case of features with lots of nas\n",
    "\n",
    "# drop na rows:\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# convert to matrices for machine learning:\n",
    "labelcol = 'hasParkinsons'\n",
    "X, y, X_names, y_name = mt.convert_features_df_to_X_and_y_for_machinelearning(features_df, labelcol)\n",
    "    \n",
    "###### perform logistic regression\n",
    "\n",
    "# do cross validation manually:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# scale features:\n",
    "stdsc = StandardScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# create logistic regression model:\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)##\n",
    "#lr = linear_model.LogisticRegression(penalty='l1', C=0.1) # with regularization\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "###### assess regression performance:\n",
    "lr.coef_\n",
    "lr.intercept_ # this is the 0 coeff?\n",
    "lr.fit(X_train_std, y_train)\n",
    "print 'training accuracy:', lr.score(X_train_std, y_train)\n",
    "print 'test accuracy:', lr.score(X_test_std, y_test) # suspiciously high..\n",
    "lr.intercept_\n",
    "lr.coef_ # only using 4 features.. which ones?\n",
    "# mt.plot_decision_regions(X_combined_std, y_combined_std, classifier=lr, test_idx=range(len(X_train_std),len(X_combined_std)+1))\n",
    "X_names_heavy = X_names[np.where(np.abs(lr.coef_) > 0.1)[1]]\n",
    "Scoef = mt.convert_regression_coefs_to_pdSeries(lr.coef_, X_names)\n",
    "\n",
    "print '\\n'\n",
    "print Scoef.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Remove features until the model fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender', 'hasParkinsons']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### define features:\n",
    "gamefeatures = ['9_numsuccesses', '9_numunsuccesses',\n",
    "                '9_gamesize', '9_meandist', '9_successful',\n",
    "                '9_gamescore', '9_latency', '9_firstdist']\n",
    "#features = [\"game_score\",\"age\",\"game_numFails\", \"phoneInfo\",\"education\", \"gender\", \"phoneUsage\", \"smartphone\", \"hasParkinsons\"]\n",
    "\n",
    "#features = gamefeatures + features\n",
    "features = gamefeatures + ['game_score', 'hasParkinsons']\n",
    "features.remove('9_successful')\n",
    "features.remove('9_numunsuccesses')\n",
    "features.remove('game_score')\n",
    "features.remove('9_firstdist')\n",
    "features.remove('9_meandist')\n",
    "features.remove('9_latency')\n",
    "features.remove('9_gamescore')\n",
    "features.remove('9_numsuccesses')\n",
    "\n",
    "features = ['gender', 'hasParkinsons']\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features converted to numbers:\n",
      "\n",
      "['gender']\n",
      "training accuracy: 0.786494357481\n",
      "test accuracy: 0.782590233546\n",
      "\n",
      "\n",
      "gender   -0.511951\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# transform features, etc.\n",
    "features_df = data[features]\n",
    "\n",
    "features_df = mt.convert_features_to_numbers(features_df)\n",
    "features_df = mt.move_col_to_end_of_df(features_df, 'hasParkinsons')\n",
    "\n",
    "# do more processing here, in case of features with lots of nas\n",
    "\n",
    "# drop na rows:\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# convert to matrices for machine learning:\n",
    "labelcol = 'hasParkinsons'\n",
    "X, y, X_names, y_name = mt.convert_features_df_to_X_and_y_for_machinelearning(features_df, labelcol)\n",
    "    \n",
    "###### perform logistic regression\n",
    "\n",
    "# do cross validation manually:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# scale features:\n",
    "stdsc = StandardScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "# create logistic regression model:\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)##\n",
    "#lr = linear_model.LogisticRegression(penalty='l1', C=0.1) # with regularization\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "###### assess regression performance:\n",
    "lr.coef_\n",
    "lr.intercept_ # this is the 0 coeff?\n",
    "lr.fit(X_train_std, y_train)\n",
    "print 'training accuracy:', lr.score(X_train_std, y_train)\n",
    "print 'test accuracy:', lr.score(X_test_std, y_test) # suspiciously high..\n",
    "lr.intercept_\n",
    "lr.coef_ # only using 4 features.. which ones?\n",
    "# mt.plot_decision_regions(X_combined_std, y_combined_std, classifier=lr, test_idx=range(len(X_train_std),len(X_combined_std)+1))\n",
    "X_names_heavy = X_names[np.where(np.abs(lr.coef_) > 0.1)[1]]\n",
    "Scoef = mt.convert_regression_coefs_to_pdSeries(lr.coef_, X_names)\n",
    "\n",
    "print '\\n'\n",
    "print Scoef.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIklqzRCRJLVmiEiSWjNEJEmt/X+22pMWHZyvJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d34cb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{True}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at predictions from model (are they all ones?):\n",
    "predicted = lr.predict(X_train_std)\n",
    "plt.hist(predicted)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "#predicted.__class__\n",
    "\n",
    "set(predicted)\n",
    "\n",
    "# model is outputting all ones...###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualize my features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9_numsuccesses',\n",
       " '9_numunsuccesses',\n",
       " '9_gamesize',\n",
       " '9_meandist',\n",
       " '9_successful',\n",
       " '9_gamescore',\n",
       " '9_latency',\n",
       " '9_firstdist',\n",
       " 'game_score',\n",
       " 'age',\n",
       " 'game_numFails',\n",
       " 'phoneInfo',\n",
       " 'education',\n",
       " 'gender',\n",
       " 'phoneUsage',\n",
       " 'smartphone',\n",
       " 'hasParkinsons']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### define features:\n",
    "gamefeatures = ['9_numsuccesses', '9_numunsuccesses',\n",
    "                '9_gamesize', '9_meandist', '9_successful',\n",
    "                '9_gamescore', '9_latency', '9_firstdist']\n",
    "\n",
    "features = [\"game_score\",\"age\",\"game_numFails\", \"phoneInfo\",\n",
    "    \"education\", \"gender\", \"phoneUsage\", \"smartphone\", \"hasParkinsons\"]\n",
    "\n",
    "features = gamefeatures + features\n",
    "\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.cov(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls per column:\n",
      "\n",
      "recordId                      0\n",
      "phoneInfo_demographic         0\n",
      "appVersion_demographic        0\n",
      "createdOn_demographic         0\n",
      "gamesdata                     0\n",
      "game_records_txt              0\n",
      "game_records                  0\n",
      "game_endDate                  0\n",
      "recordId_demographic          0\n",
      "game_numFails                 0\n",
      "game_startDate                0\n",
      "healthCode                    0\n",
      "createdOn                     0\n",
      "appVersion                    0\n",
      "hasParkinsons                 0\n",
      "game_score                    0\n",
      "game_numGames                 0\n",
      "phoneInfo                     0\n",
      "9_numsuccesses                2\n",
      "9_numunsuccesses              2\n",
      "9_gamesize                    2\n",
      "9_meandist                    2\n",
      "9_successful                  2\n",
      "9_gamescore                   2\n",
      "9_latency                     2\n",
      "9_firstdist                   2\n",
      "medTimepoint                  4\n",
      "smartphone                    5\n",
      "gender                        5\n",
      "phoneUsage                    6\n",
      "9_meanDt                      6\n",
      "9_meansuccessfuldist          7\n",
      "education                     8\n",
      "age                          15\n",
      "pastParticipation            16\n",
      "homeUsage                    16\n",
      "maritalStatus                18\n",
      "employment                   19\n",
      "medicalUsage                 21\n",
      "professionalDiagnosis        21\n",
      "isCaretaker                  22\n",
      "smoked                       51\n",
      "medicalUsageYesterday        58\n",
      "race                         79\n",
      "16_firstdist                132\n",
      "16_gamesize                 132\n",
      "16_meandist                 132\n",
      "16_numsuccesses             132\n",
      "16_gamescore                132\n",
      "16_latency                  132\n",
      "16_numunsuccesses           132\n",
      "16_successful               132\n",
      "videoUsage                  142\n",
      "brainStim                   221\n",
      "16_meanDt                   285\n",
      "16_meansuccessfuldist       286\n",
      "surgery                     521\n",
      "16_meanunsuccessfuldist     735\n",
      "medicationStartYear        1143\n",
      "healthHistory              1180\n",
      "healthcareProvider         1389\n",
      "onsetYear                  1414\n",
      "diagYear                   1722\n",
      "yearsSmoking               5488\n",
      "lastSmoked                 5559\n",
      "packsPerDay                5823\n",
      "9_meanunsuccessfuldist     6905\n",
      "4_numunsuccesses           7671\n",
      "4_gamesize                 7671\n",
      "4_meandist                 7671\n",
      "4_gamescore                7671\n",
      "4_successful               7671\n",
      "4_latency                  7671\n",
      "4_numsuccesses             7671\n",
      "4_firstdist                7671\n",
      "4_meanDt                   7677\n",
      "4_meansuccessfuldist       7679\n",
      "4_meanunsuccessfuldist     7832\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How many nans in each column?\n",
    "mt.display_num_nulls_per_column(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features converted to numbers:\n",
      "\n",
      "['gender', 'phoneUsage', 'smartphone', 'education', 'phoneInfo']\n",
      "training accuracy: 0.999452854277\n",
      "test accuracy: 0.978732454275\n",
      "[[ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.23        0.77      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.63        0.37      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.83        0.17      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.46        0.54      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.79        0.21      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17        0.83      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.67        0.33      ]\n",
      " [ 0.71        0.29      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.83        0.17      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.15        0.85      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2         0.8       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25        0.75      ]\n",
      " [ 0.37        0.63      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.42        0.58      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.65        0.35      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85646356  0.14353644]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.66        0.34      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26        0.74      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.32        0.68      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.85        0.15      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.15        0.85      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26        0.74      ]\n",
      " [ 0.28        0.72      ]\n",
      " [ 0.4         0.6       ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37        0.63      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17        0.83      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85646356  0.14353644]\n",
      " [ 0.3         0.7       ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.71        0.29      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.63        0.37      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.72        0.28      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.67        0.33      ]\n",
      " [ 0.15        0.85      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.88357937  0.11642063]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.55        0.45      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13        0.87      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.81        0.19      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.93583333  0.06416667]\n",
      " [ 0.27        0.73      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85        0.15      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.41        0.59      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.65        0.35      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39        0.61      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.35        0.65      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.58        0.42      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.88357937  0.11642063]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.61        0.39      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.67        0.33      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85        0.15      ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 0.29        0.71      ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30516667  0.69483333]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.38        0.62      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.63        0.37      ]\n",
      " [ 0.66        0.34      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.41        0.59      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2         0.8       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.3         0.7       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47        0.53      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.57        0.43      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.38        0.62      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.80702994  0.19297006]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.33        0.67      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.18        0.82      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.53        0.47      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.63        0.37      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.84        0.16      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99166667  0.00833333]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.33        0.67      ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 0.28        0.72      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.61        0.39      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.59        0.41      ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26        0.74      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.45        0.55      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.81        0.19      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37        0.63      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.27        0.73      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.26        0.74      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.68        0.32      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.22        0.78      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37        0.63      ]\n",
      " [ 0.38        0.62      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52        0.48      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.23        0.77      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.74        0.26      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.39        0.61      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.32        0.68      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.72        0.28      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 0.29        0.71      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.54        0.46      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.79        0.21      ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18        0.82      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.45        0.55      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.99166667  0.00833333]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47        0.53      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.3         0.7       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.58        0.42      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.85        0.15      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.30516667  0.69483333]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.32        0.68      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37        0.63      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.015       0.985     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.83        0.17      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.84        0.16      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.61        0.39      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.09583333  0.90416667]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.6         0.4       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17        0.83      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.4         0.6       ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.45        0.55      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.38        0.62      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.63        0.37      ]\n",
      " [ 0.79        0.21      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.71        0.29      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26        0.74      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.3         0.7       ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85        0.15      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15        0.85      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99166667  0.00833333]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18        0.82      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.13        0.87      ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8         0.2       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.4         0.6       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.81        0.19      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25        0.75      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.21        0.79      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.81        0.19      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.81        0.19      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.61        0.39      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85        0.15      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.49        0.51      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8         0.2       ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99166667  0.00833333]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.21        0.79      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18        0.82      ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.66        0.34      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15        0.85      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.6         0.4       ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15        0.85      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.66        0.34      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.64        0.36      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84        0.16      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.38        0.62      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.15        0.85      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.13        0.87      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.45        0.55      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.74        0.26      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.32        0.68      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.68        0.32      ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.01        0.99      ]]\n"
     ]
    }
   ],
   "source": [
    "##### define features:\n",
    "\n",
    "features = [\"game_score\",\"age\",\"game_numFails\", \"phoneInfo\",\n",
    "    \"education\", \"gender\", \"phoneUsage\", \"smartphone\", \"hasParkinsons\"]\n",
    "features_df, X, y, X_names, y_name, stdsc, X_train_std, X_test_std, X_combined_std, y_combined = mt.prep_memory_features_for_machine_learning(data, features, labelcol)\n",
    "\n",
    "# create model:\n",
    "mod = RandomForestClassifier(n_estimators=100)\n",
    "#lr = linear_model.LogisticRegression(penalty='l1', C=0.1) # with regularization\n",
    "mod.fit(X_train_std, y_train)\n",
    "\n",
    "###### assess performance:\n",
    "mod.fit(X_train_std, y_train)\n",
    "print 'training accuracy:', mod.score(X_train_std, y_train)\n",
    "print 'test accuracy:', mod.score(X_test_std, y_test) \n",
    "mat = mod.predict_proba(X_test_std)\n",
    "print mat\n",
    "\n",
    "# coveariance?\n",
    "\n",
    "# WORKS!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 461   30]\n",
      " [  23 1837]]\n",
      "1860\n",
      "1867\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEpCAYAAAAwO/FgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113421f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### get predictions:\n",
    "y_pred = mod.predict(X_test_std)\n",
    "[y_test, y_pred]\n",
    "sklearn.metrics.roc_auc_score(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "print sum(y_test)\n",
    "print sum(y_pred)\n",
    "sum(cm)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "#    tick_marks = np.arange(len(iris.target_names))\n",
    "#    plt.xticks(tick_marks, iris.target_names, rotation=45)\n",
    "#    plt.yticks(tick_marks, iris.target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "plot_confusion_matrix(cm_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'game_score', u'age', u'game_numFails', u'phoneInfo', u'education',\n",
       "       u'gender', u'phoneUsage', u'smartphone'], dtype=object)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which features matter?\n",
    "fi = mod.feature_importances_\n",
    "\n",
    "#S = pd.(fi, axis=features[:-1])\n",
    "fi\n",
    "X_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7834, 8)\n",
      "(7834, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "['game_score', 'age', 'game_numFails', 'phoneInfo', 'education', 'gender', 'phoneUsage', 'smartphone', 'hasParkinsons']\n",
      "[400, 90.0, 4, 'iPhone 6 Plus', 'Some high school', 'Male', 'true', 'Very easy', True]\n",
      "400.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATcAAAD7CAYAAAAPf9NJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d367090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distance matrix of X matrix (and y-column in there too):\n",
    "Xy = np.hstack((X, y.reshape(len(y),1)))\n",
    "#cov = np.cov(Xy.T)\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.imshow(cov)\n",
    "#import scipy\n",
    "import scipy.spatial.distance as dist\n",
    "\n",
    "#pd = pdist(Xy, 'euclidean')\n",
    "#pd.shape\n",
    "pd = dist.pdist(Xy.T, 'euclidean')\n",
    "pd = dist.squareform(pd)\n",
    "pd.shape\n",
    "#fig, ax = plt.subplots()\n",
    "plt.imshow(pd., interpolation='none', cmap='jet')\n",
    "plt.colorbar()\n",
    "X_names\n",
    "print features\n",
    "print [data[f].max() for f in features]\n",
    "print Xy.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redo random forest with less features..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'decision_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-fb482ba9b797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# get roc/auc info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mY_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'decision_function'"
     ]
    }
   ],
   "source": [
    "#X_test = X_test_std\n",
    "#Y_test = y_test\n",
    "#clf = mod\n",
    "sklearn.metrics.roc_auc_score(y_test, )\n",
    "\n",
    "\n",
    "# overall accuracy\n",
    "acc = clf.score(X_test,Y_test)\n",
    "\n",
    "# get roc/auc info\n",
    "Y_score = clf.decision_function(X_test)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_score)\n",
    "\n",
    "roc_auc = dict()\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# make the plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.plot(fpr, tpr, label='AUC = {0}'.format(roc_auc))        \n",
    "plt.legend(loc=\"lower right\", shadow=True, fancybox =True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
